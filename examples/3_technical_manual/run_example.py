"""
Ejemplo 3: B√∫squeda Simple en Manual T√©cnico
=============================================

Este ejemplo demuestra el uso de la estrategia SIMPLE (simple_search)
para b√∫squedas directas en documentaci√≥n t√©cnica.

Escenario:
- 1 manual t√©cnico o documentaci√≥n (manual.pdf)

El sistema realiza b√∫squeda vectorial directa sin selecci√≥n previa de documentos.
Ideal para cuando tienes un solo documento o cuando no necesitas filtrado inteligente.
"""

import os
import sys
from pathlib import Path

# A√±adir el directorio ra√≠z al path para imports
root_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root_dir))

from src.search.config import SearchPipelineConfig, SearchType
from src.search.pipeline import SearchPipeline
from src.llms.embeddings.openai_embedder import OpenAIEmbedder
from src.utils import get_logger

logger = get_logger(__name__)


def setup_pipeline():
    """Configura el pipeline de b√∫squeda simple"""
    
    # Configurar pipeline con estrategia SIMPLE
    # No requiere text_model porque no hay selecci√≥n de documentos
    config = SearchPipelineConfig(
        search_type=SearchType.SIMPLE,
        collection_name_documents="documents",
        search_limit=10
    )
    
    return SearchPipeline(config=config)


def run_manual_queries():
    """Ejecuta consultas de ejemplo sobre el manual t√©cnico"""
    
    print("=" * 80)
    print("EJEMPLO 3: B√öSQUEDA SIMPLE EN MANUAL T√âCNICO")
    print("=" * 80)
    print("\nDocumentos en el sistema:")
    print("  - manual.pdf: Manual t√©cnico o documentaci√≥n")
    print("\n" + "=" * 80 + "\n")
    
    # Queries de ejemplo t√≠picas de documentaci√≥n t√©cnica
    queries = [
        "¬øC√≥mo instalar el sistema?",
        "¬øCu√°les son los requisitos del sistema?",
        "Explica la configuraci√≥n inicial",
        "¬øC√≥mo configurar las variables de entorno?",
        "Gu√≠a de inicio r√°pido",
        "¬øC√≥mo solucionar errores comunes?",
        "¬øQu√© puertos necesito abrir?",
        "Documentaci√≥n de la API REST",
        "¬øC√≥mo hacer backup de la base de datos?",
        "Procedimiento de actualizaci√≥n del sistema"
    ]
    
    # Inicializar embedder
    embedder = OpenAIEmbedder(model="text-embedding-ada-002")
    
    # Crear pipeline
    with setup_pipeline() as pipeline:
        for i, query in enumerate(queries, 1):
            print(f"\n{'‚îÄ' * 80}")
            print(f"CONSULTA {i}: {query}")
            print('‚îÄ' * 80)
            
            try:
                # Generar embedding de la query
                query_embedding, _ = embedder.generate_embedding(text=query)
                
                # Realizar b√∫squeda simple
                # El pipeline realiza b√∫squeda vectorial directa en Milvus
                # sin selecci√≥n previa ni filtros adicionales
                results = pipeline.search(
                    query_embedding=query_embedding
                    # user_query no es necesario para SIMPLE
                    # partition_names y filter_expr son opcionales
                )
                
                # Mostrar resultados
                if results:
                    print(f"\n‚úì Encontrados {len(results)} resultados:\n")
                    for j, result in enumerate(results[:3], 1):  # Mostrar top 3
                        print(f"{j}. Documento: {result.get('file_name', 'N/A')}")
                        print(f"   Score: {result.get('score', 0):.4f}")
                        print(f"   P√°ginas: {result.get('pages', 'N/A')}")
                        print(f"   Texto: {result.get('text', '')[:200]}...")
                        print()
                else:
                    print("\n‚úó No se encontraron resultados")
                    
            except Exception as e:
                logger.error(f"Error en consulta {i}: {str(e)}", exc_info=True)
                print(f"\n‚úó Error: {str(e)}")
    
    print("\n" + "=" * 80)
    print("FIN DEL EJEMPLO")
    print("=" * 80)


def run_manual_queries_with_filters():
    """
    Ejemplo adicional: B√∫squeda simple con filtros manuales
    
    Aunque la estrategia SIMPLE no usa LLM para selecci√≥n,
    puedes proporcionar filtros manualmente si conoces el file_id
    o quieres buscar en particiones espec√≠ficas.
    """
    
    print("\n" + "=" * 80)
    print("EJEMPLO 3B: B√öSQUEDA SIMPLE CON FILTROS MANUALES")
    print("=" * 80)
    
    embedder = OpenAIEmbedder(model="text-embedding-ada-002")
    
    with setup_pipeline() as pipeline:
        query = "¬øC√≥mo configurar el sistema?"
        print(f"\nConsulta: {query}")
        
        query_embedding, _ = embedder.generate_embedding(text=query)
        
        # Ejemplo 1: B√∫squeda con filtro de tipo de archivo
        print("\n1. B√∫squeda solo en PDFs:")
        results_pdf = pipeline.search(
            query_embedding=query_embedding,
            filter_expr='type_file == "PDF"'
        )
        print(f"   Resultados: {len(results_pdf)}")
        
        # Ejemplo 2: B√∫squeda en un documento espec√≠fico (si conoces el file_id)
        print("\n2. B√∫squeda en documento espec√≠fico:")
        print("   (Requiere conocer el file_id del manual)")
        # results_specific = pipeline.search(
        #     query_embedding=query_embedding,
        #     filter_expr='file_id == "manual_123"'
        # )
        
        # Ejemplo 3: B√∫squeda en particiones espec√≠ficas
        print("\n3. B√∫squeda en particiones espec√≠ficas:")
        print("   (Si tu colecci√≥n usa particiones)")
        # results_partition = pipeline.search(
        #     query_embedding=query_embedding,
        #     partition_names=["technical_docs"]
        # )
    
    print("\n" + "=" * 80)


def main():
    """Funci√≥n principal"""
    
    print("\nüìñ Iniciando ejemplo de b√∫squeda simple en manual t√©cnico...\n")
    
    # Verificar que existe el archivo de datos
    data_dir = Path(__file__).parent / "data"
    manual_file = data_dir / "manual.pdf"
    
    if not manual_file.exists():
        print("‚ö†Ô∏è  ADVERTENCIA: No se encontr√≥ el archivo 'manual.pdf'")
        print("\nPor favor, a√±ade el manual a la carpeta 'data/' antes de ejecutar.")
        print("El archivo debe estar previamente indexado en Milvus.\n")
        
        response = input("¬øDeseas continuar de todas formas? (s/n): ")
        if response.lower() != 's':
            print("Ejemplo cancelado.")
            return
    
    try:
        # Ejecutar b√∫squedas simples
        run_manual_queries()
        
        # Ejecutar ejemplo con filtros (opcional)
        print("\n¬øDeseas ver el ejemplo con filtros manuales? (s/n): ", end="")
        if input().lower() == 's':
            run_manual_queries_with_filters()
            
    except Exception as e:
        logger.error(f"Error ejecutando el ejemplo: {str(e)}", exc_info=True)
        print(f"\n‚ùå Error: {str(e)}")
        print("\nAseg√∫rate de que:")
        print("  1. Milvus est√° corriendo (docker-compose up -d)")
        print("  2. El manual est√° indexado en la colecci√≥n 'documents'")
        print("  3. Las variables de entorno est√°n configuradas (.env)")
        print("  4. Tienes una API key v√°lida de OpenAI (para embeddings)")
        print("\nNota: Esta estrategia NO requiere LLM para b√∫squeda,")
        print("      solo para generar embeddings de las queries.")


if __name__ == "__main__":
    main()





